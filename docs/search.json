[
  {
    "objectID": "about.html#software-engineer-october-2018---august-2024",
    "href": "about.html#software-engineer-october-2018---august-2024",
    "title": "About Us",
    "section": "Software Engineer (October 2018 - August 2024)",
    "text": "Software Engineer (October 2018 - August 2024)\nIn this role, I focused on developing scalable solutions within the property management software sector. My key responsibilities included:\n\nDatabase Architecture and Optimization: Collaborated with cross-functional teams to build robust database structures and optimized SQL queries to enhance overall system efficiency.\nProduct Development: Created and deployed microservicable product which includes the improved system performance.\nClient Support: Delivering optimization solutions to enhance product performance and address client requirements.\nDatabase administration: Acted as a virtual database administrator and helped the team with various database solutions.\nProject Leading: Led various projects, contributing to project management and project support."
  },
  {
    "objectID": "about.html#associate-software-engineer-july-2017---september-2018",
    "href": "about.html#associate-software-engineer-july-2017---september-2018",
    "title": "About Us",
    "section": "Associate Software Engineer (July 2017 - September 2018)",
    "text": "Associate Software Engineer (July 2017 - September 2018)\nAs an Associate Software Engineer, I gained foundational skills in web development and database management. My contributions included:\n\nAgile Practices: Learned agile framework to deploy efficient projects, learned sprint deployment and retrospectives to ensure efficient project progress.\nTechnical Support: Provided troubleshooting assistance to resolve client issues, enhancing user experience.\nMentorship: Collaborated with senior engineers, learning advanced database management techniques and best practices."
  },
  {
    "objectID": "about.html#trainee-january-2017---june-2017",
    "href": "about.html#trainee-january-2017---june-2017",
    "title": "About Us",
    "section": "Trainee (January 2017 - June 2017)",
    "text": "Trainee (January 2017 - June 2017)\nIn this initial role, I focused on acquiring essential skills in software development and database management. My responsibilities included:\n\nTraining and Development: Engaged in training sessions with experienced engineers, laying the groundwork for my subsequent roles.\nProject Assistance: Assisted in various projects, contributing to code development and testing efforts.\n\n\nKey Projects\n\nMicroservices Architecture Development: Spearheaded a project that improved scalability by 50% and reduced deployment times.\nAWS Cloud Migration: Led the migration of 40% of client documents from on-premises servers to AWS S3, solving critical storage challenges.\nAutomated Data Import into the system: Redesigned a data module using automation with Python and OpenAI, to import 1,50,000 records every year resulting in more efficient data handling and improved eligibility calculations for affordable housing product.\nSensitive Data Encryption: Worked on encrypting sensitive resident data across the entire database to ensure compliance with security standards.\nDocument Creation automation: Developed more than 56 state-specific certification documents for affordable housing using custom scripts and database integration and automated the process of filling the certifications for every resident on certification process using object-oriented PHP, PostgreSQL, and Adobe techniques.\n\n\n\nTechnical Skills\n\nDatabases: PostgreSQL, MySQL\n\nBackend Development: PHP, Python\n\nFrontend Technologies: AJAX, HTML, JavaScript, jQuery\n\nCloud Technologies: AWS, Docker, Kubernetes\n\nFrameworks: MVC, Singleton, Fusebox\n\nAgile Tools: Jira, ClickUp\n\nVersion Control: GIT, SVN\n\n\n\nEducation\n\nMaster’s in Data Analytics Engineering\nGeorge Mason University, Virginia, USA (2024 - 2026)\nBachelor of Technology in Computer Science & Technology\nSree Venkateshwara College of Engineering, Nellore, India (2013 - 2017)"
  },
  {
    "objectID": "ResearchQuestions.html",
    "href": "ResearchQuestions.html",
    "title": "Final Project - Group 11",
    "section": "",
    "text": "RESEARCH QUESTIONS:\nResearch Question 1:\nWhat combination of factors most strongly predicts accident severity?\nModel: Random forests\nFeatures: Weather Conditions\nTarget Variable: Accident severity (categorized as Slight, Serious, and Fatal accidents)\nObjective: The number of vehicles involved is the strongest predictor of accident severity. Urban or rural area also impacts severity, likely due to differences in traffic patterns and road infrastructure. Road surface conditions and weather conditions play a smaller but notable role in influencing accident severity.\nInsights: Accidents with more vehicles tend to be more severe, as they involve higher chances of complex collisions and injuries. Urban areas may see higher severity due to dense traffic, while rural areas could have higher speeds leading to severe outcomes. Adverse weather and poor road surface conditions exacerbate accident severity, though their individual contributions are less than the number of vehicles or urban/rural classification.\nLimitations: The model underperforms for rare cases (fatal and serious accidents), likely due to imbalanced data. Additional factors (e.g., driver behavior, time of day, and speed) could improve predictions.\nResearch Question 2:\nCan the weather conditions predict accident severity?\nModel: Multinomial Logistic Regression\nFeatures: Weather Conditions\nTarget Variable: Accident severity (categorized as Slight, Serious, and Fatal accidents)\nObjective: To determine if weather conditions can predict accident severity.\nA Slight increase in weather condition values slightly raises the likelihood of higher accident severity. Coefficients for Severity 2 (Serious) and Severity 3 (Slight) suggest weather conditions play a modest role in predicting severity.\nResearch Question 3 :\nDoes Urban vs. Rural Areas affect accident severity under different weather conditions ?\nModel: Logistic Regression\nFeatures: Weather Conditions\nTarget Variable: Accident severity (categorized as Slight, Serious, and Fatal accidents)\nObjective:\nInfluence of Urban vs. Rural Areas:\nHow the location type (urban or rural) impacts the likelihood of slight accidents compared to fatal or serious ones.\nImpact of Weather:\nWhether weather conditions have a significant effect on the severity of accidents when combined with urban/rural classification.\n\n\nConcluded the analysis by continuing the Logistic Regression with Lasso.\nLogistic Regression Lasso has performed well with most significant variables predicting accident severity."
  },
  {
    "objectID": "project_source_code.html",
    "href": "project_source_code.html",
    "title": "Project Source Code",
    "section": "",
    "text": "# Load required libraries\n\nsuppressWarnings({\n library(tidyverse)\nlibrary(ggplot2)\nlibrary(plotly)  \nlibrary(maps)\nlibrary(leaflet)\nlibrary(readr)\n\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(viridis) \nlibrary(rnaturalearth)  # For loading world map data\n\n\n})\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Load the data\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Data Cleaning Steps\n# 1. Remove rows with missing or NA values in important columns\nroad_casualities &lt;- road_casualities %&gt;%\n  filter(!is.na(accident_severity), \n         !is.na(weather_conditions), \n         !is.na(road_surface_conditions))\n\n# 2. Ensure the accident_severity column has valid values (1, 2, 3)\nroad_casualities &lt;- road_casualities %&gt;%\n  filter(accident_severity %in% c(1, 2, 3))\n\n# 3. Convert necessary columns to factors\nroad_casualities$accident_severity &lt;- factor(road_casualities$accident_severity, \n                                 levels = c(1, 2, 3),\n                                 labels = c(\"Life-Threatening\", \"Significant\", \"Mild\"))\nroad_casualities$weather_conditions &lt;- as.factor(road_casualities$weather_conditions)\nroad_casualities$road_surface_conditions &lt;- as.factor(road_casualities$road_surface_conditions)\nroad_casualities$urban_or_rural_area &lt;- as.factor(road_casualities$urban_or_rural_area)\n\n# 4. Remove duplicates if any\nroad_casualities &lt;- road_casualities %&gt;% distinct()\n\n\n# Visualization with Cleaned Data\n# Assign updated custom colors for each severity level\nseverity_colors &lt;- c(\"Life-Threatening\" = \"red\", \n                     \"Significant\" = \"darkorange\", \n                     \"Mild\" = \"darkgreen\")\n\n# Create an Interactive Histogram with Updated Colors\nhistogram &lt;- ggplot(road_casualities, aes(x = accident_severity, fill = accident_severity)) +\n  geom_bar(alpha = 0.7, color = \"black\") +\n  scale_fill_manual(values = severity_colors) +\n  labs(title = \"Distribution of Accident Severity\",\n       x = \"Accident Severity\",\n       y = \"Count\") \n\n# Convert to interactive using plotly\ninteractive_histogram &lt;- ggplotly(histogram, tooltip = c(\"count\", \"x\"))\n\n# Display the interactive histogram\ninteractive_histogram\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Load dataset\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Convert time column to a usable format (assuming time is in 24-hour format)\nroad_casualities$time_of_day &lt;- as.numeric(substr(road_casualities$time, 1, 2))\n\n# Define time bands based on STATS20 guidance\nroad_casualities$time_band &lt;- cut(\n  road_casualities$time_of_day,\n  breaks = c(-1, 5, 9, 15, 19, 23),\n  labels = c(\"Night (Midnight to 5 AM)\", \n             \"Morning Rush Hour\", \n             \"Daytime\", \n             \"Evening Rush Hour\", \n             \"Night (8 PM to 11 PM)\")\n)\n\n# Aggregate the data by time bands\ntime_band_summary &lt;- road_casualities %&gt;%\n  group_by(time_band) %&gt;%\n  summarise(total_accidents = n()) %&gt;%\n  arrange(desc(total_accidents))\n\n# Create a ggplot object with gradient colors\ntime_band_plot &lt;- ggplot(time_band_summary, aes(x = time_band, y = total_accidents, fill = total_accidents)) +\n  geom_bar(stat = \"identity\", color = \"black\", alpha = 0.8) +\n  labs(\n    title = \"Accidents by Time Bands (STATS20)\",\n    x = \"Time Band\",\n    y = \"Number of Accidents\"\n  ) +\n  scale_fill_gradient(low = \"pink\", high = \"red\", name = \"Total Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Convert the plot to interactive using plotly\ninteractive_time_band_plot &lt;- ggplotly(time_band_plot, tooltip = c(\"x\", \"y\"))\n\n# Display the interactive plot\ninteractive_time_band_plot\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\n\n# Define light condition mapping (STATS20)\nlight_conditions_map &lt;- c(\n  \"1\" = \"Daylight\",\n  \"4\" = \"Dark (street lights present and lit)\",\n  \"5\" = \"Dark (street lights present but unlit)\",\n  \"6\" = \"Dark (no street lights)\",\n  \"7\" = \"Other\"\n)\n\n# Map light conditions\nroad_casualities$light_conditions &lt;- as.factor(\n  light_conditions_map[as.character(road_casualities$light_conditions)]\n)\n\n# Ensure weather conditions are mapped\nweather_conditions_map &lt;- c(\n  \"1\" = \"Fine without high winds\",\n  \"2\" = \"Raining without high winds\",\n  \"3\" = \"Snowing without high winds\",\n  \"4\" = \"Fine with high winds\",\n  \"5\" = \"Raining with high winds\",\n  \"6\" = \"Snowing with high winds\",\n  \"7\" = \"Fog or mist\",\n  \"8\" = \"Other\",\n  \"9\" = \"Unknown\"\n)\n\nroad_casualities$weather_conditions &lt;- as.factor(\n  weather_conditions_map[as.character(road_casualities$weather_conditions)]\n)\n\n# Create summary data for heatmap\nheatmap_data &lt;- road_casualities %&gt;%\n  group_by(weather_conditions, light_conditions) %&gt;%\n  summarise(total_accidents = n(), .groups = \"drop\")\n\n# Create the heatmap with data labels and contrasting colors\nheatmap_plot &lt;- ggplot(heatmap_data, aes(x = weather_conditions, y = light_conditions, fill = total_accidents)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = total_accidents), color = \"black\", size = 3) +  # Add data labels\n  scale_fill_gradient(low = \"#f9f9f9\", high = \"#d73027\", name = \"Total Accidents\") +\n  labs(\n    title = \"Accidents by Weather and Light Conditions\",\n    x = \"Weather Conditions\",\n    y = \"Light Conditions\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    axis.text.y = element_text(size = 10),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 8)\n  )\n\n# Make the heatmap interactive\ninteractive_heatmap &lt;- ggplotly(heatmap_plot, tooltip = c(\"x\", \"y\", \"fill\"))\ninteractive_heatmap\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\n\n# Load the dataset\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Define weather condition mapping\nweather_conditions_map &lt;- c(\n  \"1\" = \"Fine without high winds\",\n  \"2\" = \"Raining without high winds\",\n  \"3\" = \"Snowing without high winds\",\n  \"4\" = \"Fine with high winds\",\n  \"5\" = \"Raining with high winds\",\n  \"6\" = \"Snowing with high winds\",\n  \"7\" = \"Fog or mist\",\n  \"8\" = \"Other\",\n  \"9\" = \"Unknown\"\n)\n\n# Map weather conditions\nroad_casualities$weather_conditions_desc &lt;- as.factor(weather_conditions_map[as.character(road_casualities$weather_conditions)])\n\n# Summarize the data to get accident counts by weather condition\nweather_summary &lt;- road_casualities %&gt;%\n  group_by(weather_conditions_desc) %&gt;%\n  summarise(total_accidents = n(), .groups = \"drop\")\n\n# Add a clean label for the tooltip\nweather_summary$tooltip_label &lt;- paste0(\n  \"Weather: \", weather_summary$weather_conditions_desc, \n  \"&lt;br&gt;Total Accidents: \", weather_summary$total_accidents\n)\n\n# Create a bar plot with dynamic red shading\nweather_plot &lt;- ggplot(weather_summary, aes(\n  x = reorder(weather_conditions_desc, -total_accidents), \n  y = total_accidents, \n  fill = total_accidents, \n  text = tooltip_label  # Use clean tooltip labels\n)) +\n  geom_bar(stat = \"identity\", color = \"black\", alpha = 0.8) +\n  scale_fill_gradient(low = \"#FFC1C1\", high = \"#8B0000\", name = \"Total Accidents\") +\n  labs(\n    title = \"Accidents by Weather Conditions\",\n    x = \"Weather Conditions\",\n    y = \"Number of Accidents\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 8), # Rotate and reduce text size\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_text(size = 10)\n  )\n\n# Make it interactive and use the clean tooltip\ninteractive_weather_plot &lt;- ggplotly(weather_plot, tooltip = \"text\")\ninteractive_weather_plot\n\n\n\n\n\n\n# Load the dataset\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(plotly)\n\n# Define STATS19 road surface condition mapping\nroad_conditions_map &lt;- c(\n  \"1\" = \"Dry\",\n  \"2\" = \"Wet or damp\",\n  \"3\" = \"Snow\",\n  \"4\" = \"Frost or ice\",\n  \"5\" = \"Flood\",\n  \"6\" = \"Oil or diesel\",\n  \"7\" = \"Mud\",\n  \"8\" = \"Other\",\n  \"9\" = \"Unknown\"\n)\n\n# Step 1: Filter valid road_surface_conditions values (1 to 9)\nroad_casualities &lt;- road_casualities %&gt;%\n  filter(road_surface_conditions %in% c(1:9))\n\n# Step 2: Map road conditions to descriptions\nroad_casualities$road_conditions_desc &lt;- as.factor(\n  road_conditions_map[as.character(road_casualities$road_surface_conditions)]\n)\n\n# Debugging: Check unique values in road_conditions_desc\nprint(\"Mapped descriptions:\")\n\n[1] \"Mapped descriptions:\"\n\nprint(unique(road_casualities$road_conditions_desc))\n\n[1] Wet or damp  Dry          Unknown      Frost or ice Snow        \n[6] Flood       \nLevels: Dry Flood Frost or ice Snow Unknown Wet or damp\n\n# Step 3: Aggregate data by road surface condition\nroad_summary &lt;- road_casualities %&gt;%\n  group_by(road_conditions_desc) %&gt;%\n  summarise(total_accidents = n()) %&gt;%\n  arrange(desc(total_accidents))\n\n# Debugging: Check aggregated data\nprint(\"Aggregated road surface condition data:\")\n\n[1] \"Aggregated road surface condition data:\"\n\nprint(road_summary)\n\n# A tibble: 6 × 2\n  road_conditions_desc total_accidents\n  &lt;fct&gt;                          &lt;int&gt;\n1 Dry                            72752\n2 Wet or damp                    26944\n3 Unknown                         1617\n4 Frost or ice                    1461\n5 Snow                             241\n6 Flood                            179\n\n# Step 4: Create the bar plot\nroad_plot &lt;- ggplot(road_summary, aes(\n  x = reorder(road_conditions_desc, -total_accidents), \n  y = total_accidents, \n  fill = road_conditions_desc, \n  text = paste0(road_conditions_desc, \": \", total_accidents, \" accidents\")\n)) +\n  geom_bar(stat = \"identity\", alpha = 0.8, color = \"black\") +\n  labs(\n    title = \"Distribution of Accidents by Road Surface Conditions (STATS19)\",\n    x = \"Road Surface Conditions\",\n    y = \"Number of Accidents\"\n  ) +\n  scale_fill_manual(values = c(\n    \"Dry\" = \"red\",\n    \"Wet or damp\" = \"#73a2c6\",\n    \"Snow\" = \"#1b9e77\",\n    \"Frost or ice\" = \"#d95f02\",\n    \"Flood\" = \"#7570b3\",\n    \"Oil or diesel\" = \"#e7298a\",\n    \"Mud\" = \"#66a61e\",\n    \"Other\" = \"#e6ab02\",\n    \"Unknown\" = \"#a6761d\"\n  )) \n\n# Convert the plot to an interactive plot\ninteractive_road_plot &lt;- ggplotly(road_plot, tooltip = \"text\")\n\n# Display the interactive plot\ninteractive_road_plot\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(caret)\n# Load necessary libraries\nlibrary(nnet)  # For multinomial logistic regression\nlibrary(caret) # For data partitioning\n\n\n# Read the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n\n# Select relevant columns and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, c(\"accident_severity\", \"weather_conditions\")])\n\n# Convert columns to factors\ndata_cleaned$accident_severity &lt;- as.factor(data_cleaned$accident_severity)\ndata_cleaned$weather_conditions &lt;- as.numeric(data_cleaned$weather_conditions)\n\n# Split the dataset into training and testing sets\nset.seed(42)\ntrain_index &lt;- createDataPartition(data_cleaned$accident_severity, p = 0.8, list = FALSE)\ntrain_data &lt;- data_cleaned[train_index, ]\ntest_data &lt;- data_cleaned[-train_index, ]\n\n# Train multinomial logistic regression model\nmultinom_model &lt;- multinom(accident_severity ~ weather_conditions, data = train_data)\n\n# weights:  9 (4 variable)\ninitial  value 91633.053773 \niter  10 value 50406.679444\nfinal  value 50392.493956 \nconverged\n\n# Summarize the model\nsummary(multinom_model)\n\nCall:\nmultinom(formula = accident_severity ~ weather_conditions, data = train_data)\n\nCoefficients:\n  (Intercept) weather_conditions\n2     2.64414         0.06126746\n3     3.76240         0.12285242\n\nStd. Errors:\n  (Intercept) weather_conditions\n2  0.04240724         0.02156981\n3  0.04154713         0.02120177\n\nResidual Deviance: 100785 \nAIC: 100793 \n\n# Make predictions\npredictions &lt;- predict(multinom_model, newdata = test_data)\n\n# Evaluate the model\nconfusion_matrix &lt;- table(test_data$accident_severity, predictions)\nprint(\"Confusion Matrix:\")\n\n[1] \"Confusion Matrix:\"\n\nprint(confusion_matrix)\n\n   predictions\n        1     2     3\n  1     0     0   304\n  2     0     0  4687\n  3     0     0 15859\n\n# Calculate accuracy\naccuracy &lt;- sum(diag(confusion_matrix)) / sum(confusion_matrix)\nprint(paste(\"Accuracy:\", round(accuracy, 4)))\n\n[1] \"Accuracy: 0.7606\"\n\n\n\n# Load necessary libraries\nlibrary(nnet)  # For multinomial logistic regression\nlibrary(caret) # For data partitioning\nlibrary(pROC)  # For AUC and ROC curves\n\n# Read the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Select relevant columns and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, c(\"accident_severity\", \"weather_conditions\")])\n\n# Convert columns to factors and numeric types\ndata_cleaned$accident_severity &lt;- as.factor(data_cleaned$accident_severity)\ndata_cleaned$weather_conditions &lt;- as.numeric(data_cleaned$weather_conditions)\n\n# Split the dataset into training and testing sets\nset.seed(42)\ntrain_index &lt;- createDataPartition(data_cleaned$accident_severity, p = 0.8, list = FALSE)\ntrain_data &lt;- data_cleaned[train_index, ]\ntest_data &lt;- data_cleaned[-train_index, ]\n\n# Train multinomial logistic regression model\nmultinom_model &lt;- multinom(accident_severity ~ weather_conditions, data = train_data)\n\n# weights:  9 (4 variable)\ninitial  value 91633.053773 \niter  10 value 50406.679444\nfinal  value 50392.493956 \nconverged\n\n# Predict probabilities for the test data\nprobabilities &lt;- predict(multinom_model, newdata = test_data, type = \"probs\")\n\n# Create one-vs-all ROC curves for each class\nroc_curve_1 &lt;- roc(as.numeric(test_data$accident_severity == 1), probabilities[, 1], plot = TRUE, col = \"red\", main = \"ROC Curve for Multinomial Logistic Regression\")\nroc_curve_2 &lt;- roc(as.numeric(test_data$accident_severity == 2), probabilities[, 2], plot = TRUE, col = \"blue\", add = TRUE)\nroc_curve_3 &lt;- roc(as.numeric(test_data$accident_severity == 3), probabilities[, 3], plot = TRUE, col = \"green\", add = TRUE)\n\n# Add legend\nlegend(\"bottomright\", legend = c(\"Class 1 (Fatal)\", \"Class 2 (Serious)\", \"Class 3 (Slight)\"),\n       col = c(\"red\", \"blue\", \"green\"), lwd = 2)\n\n\n\n\n\n\n\n# Compute AUC for each class\nauc_1 &lt;- auc(roc_curve_1)\nauc_2 &lt;- auc(roc_curve_2)\nauc_3 &lt;- auc(roc_curve_3)\n\n\nlibrary(ggplot2)\neffect_data &lt;- data.frame(\n  weather_conditions = seq(min(train_data$weather_conditions), max(train_data$weather_conditions), length.out = 100)\n)\neffect_data$prob_class1 &lt;- predict(multinom_model, newdata = effect_data, type = \"probs\")[, 1]\neffect_data$prob_class2 &lt;- predict(multinom_model, newdata = effect_data, type = \"probs\")[, 2]\neffect_data$prob_class3 &lt;- predict(multinom_model, newdata = effect_data, type = \"probs\")[, 3]\n\nggplot(effect_data, aes(x = weather_conditions)) +\n  geom_line(aes(y = prob_class1, color = \"Class 1\")) +\n  geom_line(aes(y = prob_class2, color = \"Class 2\")) +\n  geom_line(aes(y = prob_class3, color = \"Class 3\")) +\n  labs(title = \"Effect of Weather Conditions on Accident Severity\",\n       y = \"Probability\", x = \"Weather Conditions\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"red\", \"blue\", \"green\"))\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\n# Load necessary libraries\nlibrary(randomForest)\nlibrary(pROC)\nlibrary(caret)\n\n# Read the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Select relevant features and target variable\nfeatures &lt;- c(\"weather_conditions\", \"number_of_vehicles\", \"road_surface_conditions\", \"urban_or_rural_area\")\ntarget &lt;- \"accident_severity\"\n\n# Filter data to include only relevant columns and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, c(features, target)])\n\n# Convert target variable to factor for classification\ndata_cleaned$accident_severity &lt;- as.factor(data_cleaned$accident_severity)\n\n# Split data into training and testing sets\nset.seed(42)\ntrain_index &lt;- createDataPartition(data_cleaned$accident_severity, p = 0.8, list = FALSE)\ntrain_data &lt;- data_cleaned[train_index, ]\ntest_data &lt;- data_cleaned[-train_index, ]\n\n# Train a Random Forest model\nrf_model &lt;- randomForest(\n  accident_severity ~ .,\n  data = train_data,\n  ntree = 100,\n  importance = TRUE\n)\n\n# Print model summary\nprint(rf_model)\n\n\nCall:\n randomForest(formula = accident_severity ~ ., data = train_data,      ntree = 100, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 100\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 23.95%\nConfusion matrix:\n  1  2     3  class.error\n1 0  0  1218 1.0000000000\n2 0  6 18745 0.9996800171\n3 0 15 63424 0.0002364476\n\n# Predict probabilities on the test set\nrf_probabilities &lt;- predict(rf_model, newdata = test_data, type = \"prob\")\n\n# Draw AUC Curve for each class using one-vs-all approach\nauc_values &lt;- list()\nfor (i in 1:ncol(rf_probabilities)) {\n  class_label &lt;- colnames(rf_probabilities)[i]\n  roc_curve &lt;- roc(as.numeric(test_data$accident_severity == class_label), \n                   rf_probabilities[, i], \n                   plot = TRUE, \n                   main = paste(\"ROC Curve for Class\", class_label), \n                   col = i)\n  auc_values[[class_label]] &lt;- auc(roc_curve)\n  print(paste(\"AUC for Class\", class_label, \":\", round(auc(roc_curve), 4)))\n}\n\n\n\n\n\n\n\n\n[1] \"AUC for Class 1 : 0.4996\"\n\n\n\n\n\n\n\n\n\n[1] \"AUC for Class 2 : 0.5012\"\n\n\n\n\n\n\n\n\n\n[1] \"AUC for Class 3 : 0.5012\"\n\n# Visualize feature importance\nvarImpPlot(rf_model)"
  },
  {
    "objectID": "project_source_code.html#loading-libraries",
    "href": "project_source_code.html#loading-libraries",
    "title": "Project Source Code",
    "section": "",
    "text": "# Load required libraries\n\nsuppressWarnings({\n library(tidyverse)\nlibrary(ggplot2)\nlibrary(plotly)  \nlibrary(maps)\nlibrary(leaflet)\nlibrary(readr)\n\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(viridis) \nlibrary(rnaturalearth)  # For loading world map data\n\n\n})\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Load the data\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Data Cleaning Steps\n# 1. Remove rows with missing or NA values in important columns\nroad_casualities &lt;- road_casualities %&gt;%\n  filter(!is.na(accident_severity), \n         !is.na(weather_conditions), \n         !is.na(road_surface_conditions))\n\n# 2. Ensure the accident_severity column has valid values (1, 2, 3)\nroad_casualities &lt;- road_casualities %&gt;%\n  filter(accident_severity %in% c(1, 2, 3))\n\n# 3. Convert necessary columns to factors\nroad_casualities$accident_severity &lt;- factor(road_casualities$accident_severity, \n                                 levels = c(1, 2, 3),\n                                 labels = c(\"Life-Threatening\", \"Significant\", \"Mild\"))\nroad_casualities$weather_conditions &lt;- as.factor(road_casualities$weather_conditions)\nroad_casualities$road_surface_conditions &lt;- as.factor(road_casualities$road_surface_conditions)\nroad_casualities$urban_or_rural_area &lt;- as.factor(road_casualities$urban_or_rural_area)\n\n# 4. Remove duplicates if any\nroad_casualities &lt;- road_casualities %&gt;% distinct()\n\n\n# Visualization with Cleaned Data\n# Assign updated custom colors for each severity level\nseverity_colors &lt;- c(\"Life-Threatening\" = \"red\", \n                     \"Significant\" = \"darkorange\", \n                     \"Mild\" = \"darkgreen\")\n\n# Create an Interactive Histogram with Updated Colors\nhistogram &lt;- ggplot(road_casualities, aes(x = accident_severity, fill = accident_severity)) +\n  geom_bar(alpha = 0.7, color = \"black\") +\n  scale_fill_manual(values = severity_colors) +\n  labs(title = \"Distribution of Accident Severity\",\n       x = \"Accident Severity\",\n       y = \"Count\") \n\n# Convert to interactive using plotly\ninteractive_histogram &lt;- ggplotly(histogram, tooltip = c(\"count\", \"x\"))\n\n# Display the interactive histogram\ninteractive_histogram\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Load dataset\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Convert time column to a usable format (assuming time is in 24-hour format)\nroad_casualities$time_of_day &lt;- as.numeric(substr(road_casualities$time, 1, 2))\n\n# Define time bands based on STATS20 guidance\nroad_casualities$time_band &lt;- cut(\n  road_casualities$time_of_day,\n  breaks = c(-1, 5, 9, 15, 19, 23),\n  labels = c(\"Night (Midnight to 5 AM)\", \n             \"Morning Rush Hour\", \n             \"Daytime\", \n             \"Evening Rush Hour\", \n             \"Night (8 PM to 11 PM)\")\n)\n\n# Aggregate the data by time bands\ntime_band_summary &lt;- road_casualities %&gt;%\n  group_by(time_band) %&gt;%\n  summarise(total_accidents = n()) %&gt;%\n  arrange(desc(total_accidents))\n\n# Create a ggplot object with gradient colors\ntime_band_plot &lt;- ggplot(time_band_summary, aes(x = time_band, y = total_accidents, fill = total_accidents)) +\n  geom_bar(stat = \"identity\", color = \"black\", alpha = 0.8) +\n  labs(\n    title = \"Accidents by Time Bands (STATS20)\",\n    x = \"Time Band\",\n    y = \"Number of Accidents\"\n  ) +\n  scale_fill_gradient(low = \"pink\", high = \"red\", name = \"Total Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Convert the plot to interactive using plotly\ninteractive_time_band_plot &lt;- ggplotly(time_band_plot, tooltip = c(\"x\", \"y\"))\n\n# Display the interactive plot\ninteractive_time_band_plot\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\n\n# Define light condition mapping (STATS20)\nlight_conditions_map &lt;- c(\n  \"1\" = \"Daylight\",\n  \"4\" = \"Dark (street lights present and lit)\",\n  \"5\" = \"Dark (street lights present but unlit)\",\n  \"6\" = \"Dark (no street lights)\",\n  \"7\" = \"Other\"\n)\n\n# Map light conditions\nroad_casualities$light_conditions &lt;- as.factor(\n  light_conditions_map[as.character(road_casualities$light_conditions)]\n)\n\n# Ensure weather conditions are mapped\nweather_conditions_map &lt;- c(\n  \"1\" = \"Fine without high winds\",\n  \"2\" = \"Raining without high winds\",\n  \"3\" = \"Snowing without high winds\",\n  \"4\" = \"Fine with high winds\",\n  \"5\" = \"Raining with high winds\",\n  \"6\" = \"Snowing with high winds\",\n  \"7\" = \"Fog or mist\",\n  \"8\" = \"Other\",\n  \"9\" = \"Unknown\"\n)\n\nroad_casualities$weather_conditions &lt;- as.factor(\n  weather_conditions_map[as.character(road_casualities$weather_conditions)]\n)\n\n# Create summary data for heatmap\nheatmap_data &lt;- road_casualities %&gt;%\n  group_by(weather_conditions, light_conditions) %&gt;%\n  summarise(total_accidents = n(), .groups = \"drop\")\n\n# Create the heatmap with data labels and contrasting colors\nheatmap_plot &lt;- ggplot(heatmap_data, aes(x = weather_conditions, y = light_conditions, fill = total_accidents)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = total_accidents), color = \"black\", size = 3) +  # Add data labels\n  scale_fill_gradient(low = \"#f9f9f9\", high = \"#d73027\", name = \"Total Accidents\") +\n  labs(\n    title = \"Accidents by Weather and Light Conditions\",\n    x = \"Weather Conditions\",\n    y = \"Light Conditions\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    axis.text.y = element_text(size = 10),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 8)\n  )\n\n# Make the heatmap interactive\ninteractive_heatmap &lt;- ggplotly(heatmap_plot, tooltip = c(\"x\", \"y\", \"fill\"))\ninteractive_heatmap\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\n\n# Load the dataset\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Define weather condition mapping\nweather_conditions_map &lt;- c(\n  \"1\" = \"Fine without high winds\",\n  \"2\" = \"Raining without high winds\",\n  \"3\" = \"Snowing without high winds\",\n  \"4\" = \"Fine with high winds\",\n  \"5\" = \"Raining with high winds\",\n  \"6\" = \"Snowing with high winds\",\n  \"7\" = \"Fog or mist\",\n  \"8\" = \"Other\",\n  \"9\" = \"Unknown\"\n)\n\n# Map weather conditions\nroad_casualities$weather_conditions_desc &lt;- as.factor(weather_conditions_map[as.character(road_casualities$weather_conditions)])\n\n# Summarize the data to get accident counts by weather condition\nweather_summary &lt;- road_casualities %&gt;%\n  group_by(weather_conditions_desc) %&gt;%\n  summarise(total_accidents = n(), .groups = \"drop\")\n\n# Add a clean label for the tooltip\nweather_summary$tooltip_label &lt;- paste0(\n  \"Weather: \", weather_summary$weather_conditions_desc, \n  \"&lt;br&gt;Total Accidents: \", weather_summary$total_accidents\n)\n\n# Create a bar plot with dynamic red shading\nweather_plot &lt;- ggplot(weather_summary, aes(\n  x = reorder(weather_conditions_desc, -total_accidents), \n  y = total_accidents, \n  fill = total_accidents, \n  text = tooltip_label  # Use clean tooltip labels\n)) +\n  geom_bar(stat = \"identity\", color = \"black\", alpha = 0.8) +\n  scale_fill_gradient(low = \"#FFC1C1\", high = \"#8B0000\", name = \"Total Accidents\") +\n  labs(\n    title = \"Accidents by Weather Conditions\",\n    x = \"Weather Conditions\",\n    y = \"Number of Accidents\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 8), # Rotate and reduce text size\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_text(size = 10)\n  )\n\n# Make it interactive and use the clean tooltip\ninteractive_weather_plot &lt;- ggplotly(weather_plot, tooltip = \"text\")\ninteractive_weather_plot\n\n\n\n\n\n\n# Load the dataset\nroad_casualities &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(plotly)\n\n# Define STATS19 road surface condition mapping\nroad_conditions_map &lt;- c(\n  \"1\" = \"Dry\",\n  \"2\" = \"Wet or damp\",\n  \"3\" = \"Snow\",\n  \"4\" = \"Frost or ice\",\n  \"5\" = \"Flood\",\n  \"6\" = \"Oil or diesel\",\n  \"7\" = \"Mud\",\n  \"8\" = \"Other\",\n  \"9\" = \"Unknown\"\n)\n\n# Step 1: Filter valid road_surface_conditions values (1 to 9)\nroad_casualities &lt;- road_casualities %&gt;%\n  filter(road_surface_conditions %in% c(1:9))\n\n# Step 2: Map road conditions to descriptions\nroad_casualities$road_conditions_desc &lt;- as.factor(\n  road_conditions_map[as.character(road_casualities$road_surface_conditions)]\n)\n\n# Debugging: Check unique values in road_conditions_desc\nprint(\"Mapped descriptions:\")\n\n[1] \"Mapped descriptions:\"\n\nprint(unique(road_casualities$road_conditions_desc))\n\n[1] Wet or damp  Dry          Unknown      Frost or ice Snow        \n[6] Flood       \nLevels: Dry Flood Frost or ice Snow Unknown Wet or damp\n\n# Step 3: Aggregate data by road surface condition\nroad_summary &lt;- road_casualities %&gt;%\n  group_by(road_conditions_desc) %&gt;%\n  summarise(total_accidents = n()) %&gt;%\n  arrange(desc(total_accidents))\n\n# Debugging: Check aggregated data\nprint(\"Aggregated road surface condition data:\")\n\n[1] \"Aggregated road surface condition data:\"\n\nprint(road_summary)\n\n# A tibble: 6 × 2\n  road_conditions_desc total_accidents\n  &lt;fct&gt;                          &lt;int&gt;\n1 Dry                            72752\n2 Wet or damp                    26944\n3 Unknown                         1617\n4 Frost or ice                    1461\n5 Snow                             241\n6 Flood                            179\n\n# Step 4: Create the bar plot\nroad_plot &lt;- ggplot(road_summary, aes(\n  x = reorder(road_conditions_desc, -total_accidents), \n  y = total_accidents, \n  fill = road_conditions_desc, \n  text = paste0(road_conditions_desc, \": \", total_accidents, \" accidents\")\n)) +\n  geom_bar(stat = \"identity\", alpha = 0.8, color = \"black\") +\n  labs(\n    title = \"Distribution of Accidents by Road Surface Conditions (STATS19)\",\n    x = \"Road Surface Conditions\",\n    y = \"Number of Accidents\"\n  ) +\n  scale_fill_manual(values = c(\n    \"Dry\" = \"red\",\n    \"Wet or damp\" = \"#73a2c6\",\n    \"Snow\" = \"#1b9e77\",\n    \"Frost or ice\" = \"#d95f02\",\n    \"Flood\" = \"#7570b3\",\n    \"Oil or diesel\" = \"#e7298a\",\n    \"Mud\" = \"#66a61e\",\n    \"Other\" = \"#e6ab02\",\n    \"Unknown\" = \"#a6761d\"\n  )) \n\n# Convert the plot to an interactive plot\ninteractive_road_plot &lt;- ggplotly(road_plot, tooltip = \"text\")\n\n# Display the interactive plot\ninteractive_road_plot\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(caret)\n# Load necessary libraries\nlibrary(nnet)  # For multinomial logistic regression\nlibrary(caret) # For data partitioning\n\n\n# Read the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n\n# Select relevant columns and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, c(\"accident_severity\", \"weather_conditions\")])\n\n# Convert columns to factors\ndata_cleaned$accident_severity &lt;- as.factor(data_cleaned$accident_severity)\ndata_cleaned$weather_conditions &lt;- as.numeric(data_cleaned$weather_conditions)\n\n# Split the dataset into training and testing sets\nset.seed(42)\ntrain_index &lt;- createDataPartition(data_cleaned$accident_severity, p = 0.8, list = FALSE)\ntrain_data &lt;- data_cleaned[train_index, ]\ntest_data &lt;- data_cleaned[-train_index, ]\n\n# Train multinomial logistic regression model\nmultinom_model &lt;- multinom(accident_severity ~ weather_conditions, data = train_data)\n\n# weights:  9 (4 variable)\ninitial  value 91633.053773 \niter  10 value 50406.679444\nfinal  value 50392.493956 \nconverged\n\n# Summarize the model\nsummary(multinom_model)\n\nCall:\nmultinom(formula = accident_severity ~ weather_conditions, data = train_data)\n\nCoefficients:\n  (Intercept) weather_conditions\n2     2.64414         0.06126746\n3     3.76240         0.12285242\n\nStd. Errors:\n  (Intercept) weather_conditions\n2  0.04240724         0.02156981\n3  0.04154713         0.02120177\n\nResidual Deviance: 100785 \nAIC: 100793 \n\n# Make predictions\npredictions &lt;- predict(multinom_model, newdata = test_data)\n\n# Evaluate the model\nconfusion_matrix &lt;- table(test_data$accident_severity, predictions)\nprint(\"Confusion Matrix:\")\n\n[1] \"Confusion Matrix:\"\n\nprint(confusion_matrix)\n\n   predictions\n        1     2     3\n  1     0     0   304\n  2     0     0  4687\n  3     0     0 15859\n\n# Calculate accuracy\naccuracy &lt;- sum(diag(confusion_matrix)) / sum(confusion_matrix)\nprint(paste(\"Accuracy:\", round(accuracy, 4)))\n\n[1] \"Accuracy: 0.7606\"\n\n\n\n# Load necessary libraries\nlibrary(nnet)  # For multinomial logistic regression\nlibrary(caret) # For data partitioning\nlibrary(pROC)  # For AUC and ROC curves\n\n# Read the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Select relevant columns and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, c(\"accident_severity\", \"weather_conditions\")])\n\n# Convert columns to factors and numeric types\ndata_cleaned$accident_severity &lt;- as.factor(data_cleaned$accident_severity)\ndata_cleaned$weather_conditions &lt;- as.numeric(data_cleaned$weather_conditions)\n\n# Split the dataset into training and testing sets\nset.seed(42)\ntrain_index &lt;- createDataPartition(data_cleaned$accident_severity, p = 0.8, list = FALSE)\ntrain_data &lt;- data_cleaned[train_index, ]\ntest_data &lt;- data_cleaned[-train_index, ]\n\n# Train multinomial logistic regression model\nmultinom_model &lt;- multinom(accident_severity ~ weather_conditions, data = train_data)\n\n# weights:  9 (4 variable)\ninitial  value 91633.053773 \niter  10 value 50406.679444\nfinal  value 50392.493956 \nconverged\n\n# Predict probabilities for the test data\nprobabilities &lt;- predict(multinom_model, newdata = test_data, type = \"probs\")\n\n# Create one-vs-all ROC curves for each class\nroc_curve_1 &lt;- roc(as.numeric(test_data$accident_severity == 1), probabilities[, 1], plot = TRUE, col = \"red\", main = \"ROC Curve for Multinomial Logistic Regression\")\nroc_curve_2 &lt;- roc(as.numeric(test_data$accident_severity == 2), probabilities[, 2], plot = TRUE, col = \"blue\", add = TRUE)\nroc_curve_3 &lt;- roc(as.numeric(test_data$accident_severity == 3), probabilities[, 3], plot = TRUE, col = \"green\", add = TRUE)\n\n# Add legend\nlegend(\"bottomright\", legend = c(\"Class 1 (Fatal)\", \"Class 2 (Serious)\", \"Class 3 (Slight)\"),\n       col = c(\"red\", \"blue\", \"green\"), lwd = 2)\n\n\n\n\n\n\n\n# Compute AUC for each class\nauc_1 &lt;- auc(roc_curve_1)\nauc_2 &lt;- auc(roc_curve_2)\nauc_3 &lt;- auc(roc_curve_3)\n\n\nlibrary(ggplot2)\neffect_data &lt;- data.frame(\n  weather_conditions = seq(min(train_data$weather_conditions), max(train_data$weather_conditions), length.out = 100)\n)\neffect_data$prob_class1 &lt;- predict(multinom_model, newdata = effect_data, type = \"probs\")[, 1]\neffect_data$prob_class2 &lt;- predict(multinom_model, newdata = effect_data, type = \"probs\")[, 2]\neffect_data$prob_class3 &lt;- predict(multinom_model, newdata = effect_data, type = \"probs\")[, 3]\n\nggplot(effect_data, aes(x = weather_conditions)) +\n  geom_line(aes(y = prob_class1, color = \"Class 1\")) +\n  geom_line(aes(y = prob_class2, color = \"Class 2\")) +\n  geom_line(aes(y = prob_class3, color = \"Class 3\")) +\n  labs(title = \"Effect of Weather Conditions on Accident Severity\",\n       y = \"Probability\", x = \"Weather Conditions\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"red\", \"blue\", \"green\"))\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\n# Load necessary libraries\nlibrary(randomForest)\nlibrary(pROC)\nlibrary(caret)\n\n# Read the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Select relevant features and target variable\nfeatures &lt;- c(\"weather_conditions\", \"number_of_vehicles\", \"road_surface_conditions\", \"urban_or_rural_area\")\ntarget &lt;- \"accident_severity\"\n\n# Filter data to include only relevant columns and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, c(features, target)])\n\n# Convert target variable to factor for classification\ndata_cleaned$accident_severity &lt;- as.factor(data_cleaned$accident_severity)\n\n# Split data into training and testing sets\nset.seed(42)\ntrain_index &lt;- createDataPartition(data_cleaned$accident_severity, p = 0.8, list = FALSE)\ntrain_data &lt;- data_cleaned[train_index, ]\ntest_data &lt;- data_cleaned[-train_index, ]\n\n# Train a Random Forest model\nrf_model &lt;- randomForest(\n  accident_severity ~ .,\n  data = train_data,\n  ntree = 100,\n  importance = TRUE\n)\n\n# Print model summary\nprint(rf_model)\n\n\nCall:\n randomForest(formula = accident_severity ~ ., data = train_data,      ntree = 100, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 100\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 23.95%\nConfusion matrix:\n  1  2     3  class.error\n1 0  0  1218 1.0000000000\n2 0  6 18745 0.9996800171\n3 0 15 63424 0.0002364476\n\n# Predict probabilities on the test set\nrf_probabilities &lt;- predict(rf_model, newdata = test_data, type = \"prob\")\n\n# Draw AUC Curve for each class using one-vs-all approach\nauc_values &lt;- list()\nfor (i in 1:ncol(rf_probabilities)) {\n  class_label &lt;- colnames(rf_probabilities)[i]\n  roc_curve &lt;- roc(as.numeric(test_data$accident_severity == class_label), \n                   rf_probabilities[, i], \n                   plot = TRUE, \n                   main = paste(\"ROC Curve for Class\", class_label), \n                   col = i)\n  auc_values[[class_label]] &lt;- auc(roc_curve)\n  print(paste(\"AUC for Class\", class_label, \":\", round(auc(roc_curve), 4)))\n}\n\n\n\n\n\n\n\n\n[1] \"AUC for Class 1 : 0.4996\"\n\n\n\n\n\n\n\n\n\n[1] \"AUC for Class 2 : 0.5012\"\n\n\n\n\n\n\n\n\n\n[1] \"AUC for Class 3 : 0.5012\"\n\n# Visualize feature importance\nvarImpPlot(rf_model)"
  },
  {
    "objectID": "project_source_code.html#only-logistic-regression-with-2-variables",
    "href": "project_source_code.html#only-logistic-regression-with-2-variables",
    "title": "Project Source Code",
    "section": "only Logistic regression with 2 variables",
    "text": "only Logistic regression with 2 variables\n\n# Load necessary libraries\nlibrary(nnet)    # For logistic regression\nlibrary(pROC)    # For ROC curve and AUC\nlibrary(caret)   # For data partitioning\n\n# Read the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Select relevant columns and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, c(\"accident_severity\", \"urban_or_rural_area\", \"weather_conditions\")])\n\n# Create a binary target variable (1 for Slight, 0 for Fatal and Serious)\ndata_cleaned$binary_severity &lt;- ifelse(data_cleaned$accident_severity == 3, 1, 0)\n\n# Convert necessary columns to numeric/factor\ndata_cleaned$binary_severity &lt;- as.factor(data_cleaned$binary_severity)\ndata_cleaned$urban_or_rural_area &lt;- as.numeric(data_cleaned$urban_or_rural_area)\ndata_cleaned$weather_conditions &lt;- as.numeric(data_cleaned$weather_conditions)\n\n# Split the dataset into training and testing sets\nset.seed(42)\ntrain_index &lt;- createDataPartition(data_cleaned$binary_severity, p = 0.8, list = FALSE)\ntrain_data &lt;- data_cleaned[train_index, ]\ntest_data &lt;- data_cleaned[-train_index, ]\n\n# Train logistic regression model\nlogistic_model &lt;- glm(binary_severity ~ urban_or_rural_area + weather_conditions, \n                      data = train_data, \n                      family = binomial)\nprint(logistic_model)\n\n\nCall:  glm(formula = binary_severity ~ urban_or_rural_area + weather_conditions, \n    family = binomial, data = train_data)\n\nCoefficients:\n        (Intercept)  urban_or_rural_area   weather_conditions  \n            1.60582             -0.40781              0.06153  \n\nDegrees of Freedom: 83406 Total (i.e. Null);  83404 Residual\nNull Deviance:      91810 \nResidual Deviance: 91030    AIC: 91040\n\n# Predict probabilities for the test data\nprobabilities &lt;- predict(logistic_model, newdata = test_data, type = \"response\")\n\n# Create the ROC curve\nroc_curve &lt;- roc(test_data$binary_severity, probabilities, plot = TRUE, col = \"blue\", \n                 main = \"ROC Curve for Binary Classification\")\n\n\n\n\n\n\n\n# Compute and print AUC\nauc_value &lt;- auc(roc_curve)\nprint(paste(\"AUC Value:\", round(auc_value, 4)))\n\n[1] \"AUC Value: 0.5498\"\n\n# Add thresholds to the ROC plot\nplot(roc_curve, print.auc = TRUE, col = \"blue\")"
  },
  {
    "objectID": "project_source_code.html#logistic-regression-lasso-wirth-2-combination-variables",
    "href": "project_source_code.html#logistic-regression-lasso-wirth-2-combination-variables",
    "title": "Project Source Code",
    "section": "Logistic regression Lasso wirth 2 combination variables",
    "text": "Logistic regression Lasso wirth 2 combination variables\n\nlibrary(glmnet)\n\n# Prepare data for glmnet\nX &lt;- as.matrix(train_data[, c(\"urban_or_rural_area\", \"weather_conditions\")])\ny &lt;- as.numeric(train_data$binary_severity) - 1\n\n# Train Lasso logistic regression\nlasso_model &lt;- cv.glmnet(X, y, family = \"binomial\", alpha = 1)\n\n# Predict probabilities for test data\ntest_X &lt;- as.matrix(test_data[, c(\"urban_or_rural_area\", \"weather_conditions\")])\nlasso_probabilities &lt;- predict(lasso_model, newx = test_X, s = \"lambda.min\", type = \"response\")\n\n# Evaluate using ROC and AUC\nlasso_roc &lt;- roc(as.numeric(test_data$binary_severity), lasso_probabilities, plot = TRUE, col = \"blue\",\n                 main = \"ROC Curve for Lasso Logistic Regression\")\n\n\n\n\n\n\n\nlasso_auc &lt;- auc(lasso_roc)\nprint(paste(\"Lasso Logistic Regression AUC:\", round(lasso_auc, 4)))\n\n[1] \"Lasso Logistic Regression AUC: 0.5514\""
  },
  {
    "objectID": "project_source_code.html#logistic-regression-lasso-wirth-more-variables",
    "href": "project_source_code.html#logistic-regression-lasso-wirth-more-variables",
    "title": "Project Source Code",
    "section": "Logistic regression Lasso wirth more variables",
    "text": "Logistic regression Lasso wirth more variables\n\n# Load necessary libraries\nlibrary(glmnet)\nlibrary(pROC)\n\n# Load the dataset\ndata &lt;- read.csv(\"C:\\\\Users\\\\Venkata\\\\Desktop\\\\stat1\\\\Final project\\\\casualty_statistics.csv\")\n\n# Define selected features and target variable\nselected_features &lt;- c(\"accident_severity\", \"number_of_vehicles\", \"road_surface_conditions\", \n                       \"weather_conditions\", \"urban_or_rural_area\", \"special_conditions_at_site\", \n                       \"day_of_week\", \"time\", \"junction_detail\", \"speed_limit\")\n\n# Check if selected features exist in the dataset\nif (!all(selected_features %in% colnames(data))) {\n  missing_features &lt;- selected_features[!selected_features %in% colnames(data)]\n  stop(paste(\"The following features are missing from the dataset:\", paste(missing_features, collapse = \", \")))\n}\n\n# Filter the dataset for selected features and remove rows with missing values\ndata_cleaned &lt;- na.omit(data[, selected_features])\n\n# Create a binary target variable for classification\n# Severe (1) = accident_severity 1 or 2, Slight (0) = accident_severity 3\ndata_cleaned$binary_severity &lt;- ifelse(data_cleaned$accident_severity == 3, 0, 1)\n\n# Feature engineering: Convert 'time' into 'time_of_day' (e.g., Morning, Afternoon, Night)\ndata_cleaned$time &lt;- as.numeric(sub(\"^(\\\\d{2}):.*$\", \"\\\\1\", data_cleaned$time)) # Extract hour\ndata_cleaned$time_of_day &lt;- cut(data_cleaned$time, \n                                breaks = c(-1, 6, 12, 18, 24), \n                                labels = c(\"Night\", \"Morning\", \"Afternoon\", \"Evening\"))\n\n# Drop unnecessary columns (original 'time' and 'accident_severity')\ndata_cleaned &lt;- data_cleaned[, !(names(data_cleaned) %in% c(\"time\", \"accident_severity\"))]\n\n# Convert categorical variables into factors\ncategorical_vars &lt;- c(\"road_surface_conditions\", \"weather_conditions\", \"urban_or_rural_area\", \n                      \"special_conditions_at_site\", \"day_of_week\", \"time_of_day\", \"junction_detail\")\ndata_cleaned[categorical_vars] &lt;- lapply(data_cleaned[categorical_vars], as.factor)\n\n# Prepare data for glmnet\nX &lt;- model.matrix(binary_severity ~ ., data_cleaned)[, -1] # Remove intercept\ny &lt;- data_cleaned$binary_severity\n\n# Split data into training and testing sets\nset.seed(42)\ntrain_index &lt;- sample(1:nrow(X), size = 0.8 * nrow(X))\ntrain_X &lt;- X[train_index, ]\ntrain_y &lt;- y[train_index]\ntest_X &lt;- X[-train_index, ]\ntest_y &lt;- y[-train_index]\n\n# Train Lasso Logistic Regression model\nlasso_model &lt;- cv.glmnet(train_X, train_y, family = \"binomial\", alpha = 1)\n\n# Predict probabilities for test data\nlasso_probabilities &lt;- predict(lasso_model, newx = test_X, s = \"lambda.min\", type = \"response\")\n\n# Evaluate using ROC and AUC\nlasso_roc &lt;- roc(test_y, lasso_probabilities, plot = TRUE, col = \"blue\",\n                 main = \"ROC Curve for Lasso Logistic Regression\")\n\n\n\n\n\n\n\nlasso_auc &lt;- auc(lasso_roc)\nprint(paste(\"Lasso Logistic Regression AUC:\", round(lasso_auc, 4)))\n\n[1] \"Lasso Logistic Regression AUC: 0.612\"\n\n# Feature importance (coefficients)\ncoefficients &lt;- coef(lasso_model, s = \"lambda.min\")\nprint(\"Selected Features and Coefficients:\")\n\n[1] \"Selected Features and Coefficients:\"\n\nprint(coefficients)\n\n48 x 1 sparse Matrix of class \"dgCMatrix\"\n                                      s1\n(Intercept)                 -1.159394968\nnumber_of_vehicles          -0.256295633\nroad_surface_conditions1     0.937290733\nroad_surface_conditions2     0.925376470\nroad_surface_conditions3     0.958261001\nroad_surface_conditions4     0.708252313\nroad_surface_conditions5     0.944823220\nroad_surface_conditions9     0.445159967\nweather_conditions2         -0.069904189\nweather_conditions3         -0.117426522\nweather_conditions4          0.155343359\nweather_conditions5         -0.040067944\nweather_conditions6         -0.075081224\nweather_conditions7         -0.284458507\nweather_conditions8         -0.169295042\nweather_conditions9         -0.383972781\nurban_or_rural_area1        -0.112744643\nurban_or_rural_area2         0.086384660\nurban_or_rural_area3         0.973339463\nspecial_conditions_at_site0 -0.306314034\nspecial_conditions_at_site1 -0.507191456\nspecial_conditions_at_site2  0.314806500\nspecial_conditions_at_site3 -0.115356865\nspecial_conditions_at_site4 -0.412954815\nspecial_conditions_at_site5 -0.116574223\nspecial_conditions_at_site6 -0.353961785\nspecial_conditions_at_site7 -0.336745861\nspecial_conditions_at_site9 -1.031307541\nday_of_week2                -0.136292827\nday_of_week3                -0.175948703\nday_of_week4                -0.120039691\nday_of_week5                -0.124894449\nday_of_week6                -0.104736531\nday_of_week7                -0.002913686\njunction_detail0             0.091600324\njunction_detail1            -0.453624650\njunction_detail2            -0.188097911\njunction_detail3             .          \njunction_detail5            -0.201307564\njunction_detail6             0.008137821\njunction_detail7             .          \njunction_detail8             .          \njunction_detail9             0.001650131\njunction_detail99           -1.819330521\nspeed_limit                  0.007150706\ntime_of_dayMorning          -0.318457391\ntime_of_dayAfternoon        -0.265087170\ntime_of_dayEvening          -0.113424581"
  },
  {
    "objectID": "CrashClarity.html",
    "href": "CrashClarity.html",
    "title": "CRASH CLARITY",
    "section": "",
    "text": "ABSTRACT\nRoad accidents and safety remain critical public health concerns worldwide, with significant societal, economic, and emotional impacts. In the United Kingdom, the government provides comprehensive data on road accidents through its Road Accident and Safety Statistics guidance. This academic project leverages these statistics to analyze and interpret the trends, patterns, and contributing factors associated with road accidents in the UK.\nThe study explores key variables such as accident severity, weather and road conditions, time of day, and demographic factors, providing actionable insights into the circumstances under which accidents are most likely to occur. Utilizing advanced data visualization techniques, including interactive heatmaps and histograms, the project presents complex information in a clear and engaging manner to enhance understanding and foster data-driven decision-making.\nThe findings emphasize the critical role of environmental and behavioral factors in road safety and aim to support policymakers, researchers, and road users in designing effective interventions to reduce accidents and improve safety measures. This project underscores the importance of leveraging statistical data to promote evidence-based strategies for safer transportation systems.\nVisualizing Accident Severity Distribution\nThis interactive histogram presents a comprehensive analysis of road accident severity levels categorized as Life-Threatening, Significant, and Mild. Each category is visually distinguished using a specific color palette, with red denoting Life-Threatening accidents, orange representing Significant accidents, and green for Mild cases. The visualization provides an intuitive understanding of the frequency distribution of these severity levels, enabling researchers and policymakers to identify patterns and focus on mitigating the most critical accident types. The interactivity of the graph allows for an in-depth examination of accident counts, enhancing data-driven decision-making and supporting evidence-based road safety interventions.\n\n\n\n\n\n\nTemporal Analysis of Road Accidents by Time Bands\nThis interactive visualization categorizes road accidents into five time bands: “Night (Midnight to 5 AM),” “Morning Rush Hour,” “Daytime,” “Evening Rush Hour,” and “Night (8 PM to 11 PM)” using STATS20 guidance. The bar plot highlights accident frequencies with a gradient color scheme, showing the highest occurrences during “Daytime” and “Evening Rush Hour”.\nThese insights help identify high-risk periods, enabling policymakers and researchers to develop targeted road safety strategies. The interactive design allows for detailed exploration of accident patterns.\n\n\n\n\n\n\nAccidents by Weather and Light Conditions\nThis interactive heatmap analyzes the influence of weather and light conditions on road accidents, highlighting combinations like “Fine without high winds” and “Daylight” with the highest frequencies. A gradient color scale emphasizes accident intensity, with data labels providing exact counts. The visualization aids in identifying high-risk conditions to inform targeted safety measures.\n\n\n\n\n\n\nImpact of Weather Conditions on Road Accidents\nThis interactive bar plot presents the distribution of road accidents under various weather conditions, highlighting categories such as Fine without high winds Raining without high winds, and Fog or mist. The gradient color scale, ranging from light pink to deep red, emphasizes the frequency of accidents, with higher counts visually more prominent. Tooltips provide precise accident counts for each weather condition, enhancing the interpret ability of the data.\nThe visualization reveals that the majority of accidents occur under Fine without high winds, suggesting that favorable weather does not necessarily mitigate risk. Such insights are critical for policymakers and researchers to understand environmental influences on road safety and to develop targeted prevention strategies.\n\n\n\n\n\n\nAccidents by Road Surface Conditions\nThis interactive bar plot examines the distribution of road accidents across various surface conditions based on STATS19 classifications, such as Dry, Wet or damp, and Snow. Each condition is color-coded for clarity, with tooltips providing detailed accident counts for enhanced interpretability.\nThe analysis reveals that the majority of accidents occur on Dry surfaces, followed by Wet or damp conditions, while adverse surfaces like Flood and Mud show significantly lower frequencies. These findings emphasize the need to consider surface conditions when implementing road safety measures, particularly for common scenarios like wet or dry roads. The visualization supports data-driven strategies for reducing accidents under diverse environmental conditions.\n\n\n\n\n\n\n\nRandom Forest Model to find What combination of factors most strongly predicts accident severity?\nA Random Forest model was developed to classify accident severity based on features such as weather conditions, road surface conditions, number of vehicles, and urban or rural location. The model, trained on 100 decision trees, achieved robust classification with reasonable AUC values across all severity levels, as visualized in the ROC curves for each class.\nThe feature importance plot highlights “Weather Conditions” and “Road Surface Conditions” as the most significant predictors of accident severity, followed by “Number of Vehicles” and “Urban or Rural Area.” These insights provide valuable guidance for prioritizing interventions and refining predictive models to improve road safety outcomes. The analysis underscores the importance of environmental and contextual factors in accident severity classification.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logistic Regression Analysis of Accident Severity by Weather Conditions\nA multinomial logistic regression model was developed to examine the relationship between accident severity and weather conditions using a cleaned subset of the dataset. The dataset was partitioned into training (80%) and testing (20%) subsets to ensure robust evaluation. The model achieved convergence after 10 iterations, with residual deviance and AIC values of 100785 and 100793, respectively.\nThe confusion matrix revealed that the model performed well in classifying higher severity levels, achieving an overall accuracy of 76.06%. The coefficients indicate a positive association between weather conditions and accident severity, suggesting that as adverse weather conditions increase, the likelihood of severe accidents also rises. These findings underscore the critical role of weather in road safety and provide insights for preventive measures.\nROC Curve Analysis for Multinomial Logistic Regression Model\nThe ROC curve illustrates the predictive performance of the multinomial logistic regression model in classifying accident severity levels (Fatal, Serious, and Slight) based on weather conditions. One-vs-all ROC curves were generated for each class, with distinct color coding: red for Fatal, blue for Serious, and green for Slight.\nThe curves largely overlap with the diagonal reference line, indicating limited separation between true positive and false positive rates. As a more distanced ROC curve signifies better model performance, these results suggest the need for further feature refinement or model optimization to improve classification accuracy. The AUC values, though reasonable, highlight areas for potential enhancement in predictive capability.\n\n\n# weights:  9 (4 variable)\ninitial  value 91633.053773 \niter  10 value 50406.679444\nfinal  value 50392.493956 \nconverged\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression for Binary Accident Severity Classification to predict accident severity by rural vs urban areas in certain weather conditions.\nA logistic regression model was employed to classify accident severity into binary categories: “Slight” (1) and “Fatal/Serious” (0), using features such as urban or rural area and weather conditions. The model showed a modest reduction in residual deviance (from 91810 to 91030), with an AIC of 91040, suggesting limited improvement over the null model.\nThe ROC curve yielded an AUC value of 0.5498, indicating the model’s predictive performance is slightly better than random chance. The negative coefficient for “urban_or_rural_area” suggests that accidents in urban areas are more likely to be classified as “Slight,” while the positive coefficient for “weather_conditions” implies a weak association with increased severity. Overall, the model demonstrates minimal predictive capability and requires additional features or refinement to achieve better classification accuracy and practical applicability.\n\n\n\n\n\n\n\n\n\nLasso Logistic Regression for Binary Classification of Accident Severity**\nA Lasso logistic regression model was applied to classify accident severity into binary categories (“Slight” vs. “Fatal/Serious”) using features such as urban or rural area and weather conditions. The model employed cross-validation to identify the optimal regularization parameter (lambda.min), ensuring reduced overfitting and improved generalizability.\nThe ROC curve yielded an AUC of 0.5514, indicating a marginally better performance than random guessing. The close proximity of the ROC curve to the diagonal reference line suggests limited predictive power. While the model effectively reduces feature complexity, the low AUC highlights the need for additional predictive variables or refined feature engineering to improve classification accuracy and ensure practical applicability.\n\n\n\n\n\n\n\n\n\n\n\nLasso Logistic Regression for Predicting Accident Severity including more variables\nA Lasso logistic regression model was implemented to classify accident severity into binary categories: “Severe” (1) and “Slight” (0). The model utilized key features such as road surface conditions, weather conditions, urban or rural area, and time of day. Cross-validation identified the optimal regularization parameter (lambda.min), ensuring feature selection and preventing over fitting.\nThe model achieved an AUC of 0.612, which is the highest among all models evaluated, as visualized through the ROC curve. This indicates improved predictive performance and better discriminatory power compared to earlier approaches. Feature coefficients highlighted the importance of road surface conditions and urban/rural areas as significant predictors. While the model demonstrates improved performance, further enhancements could refine its applicability for real-world scenarios."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Information",
    "section": "",
    "text": "If you would like to get in touch, feel free to reach out through the following:\n\nVenkata Lakshmi Parimala Pasupuleti\n\nEmail: venkatalakshmiparimala@gmail.com\nLinkedIn: Venkata Lakshmi Parimala Pasupuleti\n\n\n\nKiran Dabbiril\n\nEmail: dabbiru.kiran03@gmail.com\nPhone: +1 571-663-5603\n\nAnnam Kavya\n\nEmail: Annamkavya@gmail.com\n\nWe look forward to hearing from you!"
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Paving the Way to Safety: A Statistical Exploration of UK Road Accidents",
    "section": "",
    "text": "title: “Paving the Way to Safety: A Statistical Exploration of UK Road Accidents” format: html editor: visual\nInsightfully crafted by:\nVENKATA LAKSHMI PARIMALA PASUPULETI\nANNAM KAVYA\nKIRAN DABBIRIL\nRoad accidents remain a significant public health concern, impacting thousands of lives every year. By analyzing road accidents and safety statistics, we can identify trends, evaluate safety measures, and propose data-driven solutions to improve transportation systems. This project focuses on UK road accident and safety statistics, leveraging data from the government’s comprehensive guidance."
  },
  {
    "objectID": "home.html#understanding-road-safety-statistics",
    "href": "home.html#understanding-road-safety-statistics",
    "title": "Paving the Way to Safety: A Statistical Exploration of UK Road Accidents",
    "section": "Understanding Road Safety Statistics",
    "text": "Understanding Road Safety Statistics"
  },
  {
    "objectID": "References.html",
    "href": "References.html",
    "title": "References",
    "section": "",
    "text": "The data and insights used in this project are sourced from the following:\nData CSV: - casualty_statistics.csv\nClick the links above to download the CSV files used for the analysis.\n\nReferences\n[1] Department for Transport, “Road Safety Data,” data.gov.uk, [Online]. Available: https://www.data.gov.uk/dataset/cb7ae6f0-4be6-49359277-47e5ce24a11f/road-safety-data. [Accessed: Dec. 11, 2024].\n[2]“Canvas Login | Instructure,” Gmu.edu, 2024. https://canvas.gmu.edu/courses/25180/files/7132982?module_item_id=2696644&fd_cookie_set=1 (accessed Dec. 11, 2024).\n‌[3]“Creating websites with Quarto and GitHub,” YouTube. http://www.youtube.com/playlist?list=PLkrJrLs7xfbXcEKhTCKRSr2VXH4yiBeXo (accessed Dec. 11, 2024).\n‌"
  },
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "Paving the Way to Safety: A Statistical Exploration of UK Road Accidents",
    "section": "",
    "text": "Insightfully crafted by:\nVENKATA LAKSHMI PARIMALA PASUPULETI\nANNAM KAVYA\nKIRAN DABBIRIL\nRoad accidents remain a significant public health concern, impacting thousands of lives every year. By analyzing road accidents and safety statistics, we can identify trends, evaluate safety measures, and propose data-driven solutions to improve transportation systems. This project focuses on UK road accident and safety statistics, leveraging data from the government’s comprehensive guidance."
  },
  {
    "objectID": "docs/index.html#understanding-road-safety-statistics",
    "href": "docs/index.html#understanding-road-safety-statistics",
    "title": "Paving the Way to Safety: A Statistical Exploration of UK Road Accidents",
    "section": "Understanding Road Safety Statistics",
    "text": "Understanding Road Safety Statistics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Paving the Way to Safety: A Statistical Exploration of UK Road Accidents",
    "section": "",
    "text": "Insightfully crafted by:\nVENKATA LAKSHMI PARIMALA PASUPULETI\nANNAM KAVYA\nKIRAN DABBIRIL\nRoad accidents remain a significant public health concern, impacting thousands of lives every year. By analyzing road accidents and safety statistics, we can identify trends, evaluate safety measures, and propose data-driven solutions to improve transportation systems. This project focuses on UK road accident and safety statistics, leveraging data from the government’s comprehensive guidance."
  },
  {
    "objectID": "index.html#understanding-road-safety-statistics",
    "href": "index.html#understanding-road-safety-statistics",
    "title": "Paving the Way to Safety: A Statistical Exploration of UK Road Accidents",
    "section": "Understanding Road Safety Statistics",
    "text": "Understanding Road Safety Statistics"
  }
]